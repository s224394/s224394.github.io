[
  {
    "objectID": "Workingfile_website_2.html",
    "href": "Workingfile_website_2.html",
    "title": "Assignment 2 - Social Data Analysis and Visualization",
    "section": "",
    "text": "import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\ndata=pd.read_csv(\"C:/NoterDTU/6_semester/Social_data/website_2/merged_data.csv\")\n\n\nimport pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\ndata=pd.read_csv(\"C:/NoterDTU/6_semester/Social_data/website_2/merged_data.csv\")\ncrimes = data[['Category', 'Year']]\ncrimes = crimes[(crimes['Category']=='VEHICLE THEFT') & (crimes['Year']!=2025)  ]\ncrime_counts = crimes[\"Year\"].value_counts().sort_index()\ncrime_counts.plot(kind=\"bar\",color=\"indigo\",edgecolor=\"black\")\nplt.show()\n\n\n\n\n\n\n\n\n\nfocuscrimes = set(['WEAPON LAWS', 'PROSTITUTION', 'ROBBERY', 'BURGLARY', 'ASSAULT', 'DRUG/NARCOTIC', 'LARCENY/THEFT', 'VANDALISM', 'VEHICLE THEFT', 'STOLEN PROPERTY'])\n\n\ndata[\"Year\"].value_counts().sort_index().plot(kind=\"bar\",color=\"indigo\",edgecolor=\"black\")\nplt.ylabel(\"Number of crimes\")\nplt.xlabel(\"Year\")\nplt.title(\"Number of crimes per year (2003-2025)\")\n\nText(0.5, 1.0, 'Number of crimes per year (2003-2025)')\n\n\n\n\n\n\n\n\n\n\ncrimes = data[['Category', 'Year']]\ncrimes = crimes[(crimes['Category']=='VEHICLE THEFT') & (crimes['Year']!=2025)  ]\ncrime_counts = crimes[\"Year\"].value_counts().sort_index()\ncrime_counts.plot(kind=\"bar\",color=\"indigo\",edgecolor=\"black\")\nplt.show()\n\n\n\n\n\n\n\n\n\nimport pandas as pd\nimport folium\nfrom folium.plugins import HeatMapWithTime\nfrom IPython.display import display\n\n# Load data\ndf = pd.read_csv(\"C:/NoterDTU/6_semester/Social_data/website_2/merged_data.csv\")\n\n# Filter for vehicle thefts between 2003-2007\ndf_filtered = df[(df['Category'] == 'VEHICLE THEFT') & \n                 (df['Year'].between(2003, 2024))].copy()\n\n# Check if filtered data is empty\nif df_filtered.empty:\n    print(\"Warning: No data after filtering!\")\nelse:\n    print(f\"Found {len(df_filtered)} records after filtering\")\n\n# Extract relevant columns and drop NA\ndf_filtered = df_filtered[['Latitude', 'Longitude', 'Month', 'Year']].dropna()\n\n# Check for valid coordinates\nvalid_coords = df_filtered[\n    (df_filtered['Latitude'].between(-90, 90)) & \n    (df_filtered['Longitude'].between(-180, 180))\n]\nif len(valid_coords) &lt; len(df_filtered):\n    print(f\"Warning: {len(df_filtered) - len(valid_coords)} records have invalid coordinates\")\n\n# Define month mapping and order\nmonth_mapping = {\n    \"January\": 1, \"February\": 2, \"March\": 3, \"April\": 4, \n    \"May\": 5, \"June\": 6, \"July\": 7, \"August\": 8, \n    \"September\": 9, \"October\": 10, \"November\": 11, \"December\": 12\n}\nmonth_names = list(month_mapping.keys())\n\n# Create numerical month column\ndf_filtered['MonthNum'] = df_filtered['Month'].map(month_mapping)\n\n# Sort by year and month\ndf_filtered = df_filtered.sort_values(['Year', 'MonthNum'])\n\n# Prepare heat data and time index\nheat_data = []\ntime_index = []\n\nfor year in range(2003, 2025):\n    for month_num in range(1, 13):\n        month_data = df_filtered[\n            (df_filtered['Year'] == year) & \n            (df_filtered['MonthNum'] == month_num)\n        ]\n        coords = month_data[['Latitude', 'Longitude']].values.tolist()\n        heat_data.append(coords)\n        time_index.append(f\"{month_names[month_num-1]} {year}\")\n        \n        # Print count for debugging\n        print(f\"{month_names[month_num-1]} {year}: {len(coords)} points\")\n\n# Only create map if we have data\nif any(len(data) &gt; 0 for data in heat_data):\n    # Create base map\n    base_map = folium.Map(location=[37.77919, -122.41914], zoom_start=12.5)\n    \n    # Add heatmap with time\n    HeatMapWithTime(\n        heat_data,\n        index=time_index,  # Time labels showing month and year\n        auto_play=True,\n        max_opacity=0.5,\n        radius=13,\n        min_opacity=0.1,\n        gradient={0.2: 'blue', 0.4: 'lime', 0.6: 'orange', 0.8: 'red'},\n        display_index=True,\n        use_local_extrema=False, \n        name=\"Vehicle Thefts\",\n        blur=1\n    ).add_to(base_map)\n    \n    # Add layer control\n    folium.LayerControl().add_to(base_map)\n    \n    # Display map\n    display(base_map)\n\nFound 175849 records after filtering\nJanuary 2003: 1130 points\nFebruary 2003: 1085 points\nMarch 2003: 1406 points\nApril 2003: 1440 points\nMay 2003: 1296 points\nJune 2003: 1219 points\nJuly 2003: 1257 points\nAugust 2003: 1401 points\nSeptember 2003: 1373 points\nOctober 2003: 1302 points\nNovember 2003: 1175 points\nDecember 2003: 1192 points\nJanuary 2004: 1364 points\nFebruary 2004: 1315 points\nMarch 2004: 1482 points\nApril 2004: 1507 points\nMay 2004: 1602 points\nJune 2004: 1439 points\nJuly 2004: 1468 points\nAugust 2004: 1532 points\nSeptember 2004: 1404 points\nOctober 2004: 1532 points\nNovember 2004: 1550 points\nDecember 2004: 1621 points\nJanuary 2005: 1681 points\nFebruary 2005: 1362 points\nMarch 2005: 1473 points\nApril 2005: 1586 points\nMay 2005: 1580 points\nJune 2005: 1385 points\nJuly 2005: 1414 points\nAugust 2005: 1404 points\nSeptember 2005: 1420 points\nOctober 2005: 1766 points\nNovember 2005: 1714 points\nDecember 2005: 1318 points\nJanuary 2006: 604 points\nFebruary 2006: 567 points\nMarch 2006: 562 points\nApril 2006: 571 points\nMay 2006: 540 points\nJune 2006: 650 points\nJuly 2006: 671 points\nAugust 2006: 685 points\nSeptember 2006: 570 points\nOctober 2006: 628 points\nNovember 2006: 603 points\nDecember 2006: 612 points\nJanuary 2007: 521 points\nFebruary 2007: 465 points\nMarch 2007: 511 points\nApril 2007: 407 points\nMay 2007: 374 points\nJune 2007: 486 points\nJuly 2007: 633 points\nAugust 2007: 707 points\nSeptember 2007: 690 points\nOctober 2007: 616 points\nNovember 2007: 541 points\nDecember 2007: 493 points\nJanuary 2008: 518 points\nFebruary 2008: 475 points\nMarch 2008: 525 points\nApril 2008: 536 points\nMay 2008: 510 points\nJune 2008: 426 points\nJuly 2008: 460 points\nAugust 2008: 509 points\nSeptember 2008: 579 points\nOctober 2008: 575 points\nNovember 2008: 443 points\nDecember 2008: 486 points\nJanuary 2009: 545 points\nFebruary 2009: 400 points\nMarch 2009: 458 points\nApril 2009: 395 points\nMay 2009: 401 points\nJune 2009: 393 points\nJuly 2009: 435 points\nAugust 2009: 488 points\nSeptember 2009: 433 points\nOctober 2009: 414 points\nNovember 2009: 434 points\nDecember 2009: 374 points\nJanuary 2010: 366 points\nFebruary 2010: 363 points\nMarch 2010: 351 points\nApril 2010: 325 points\nMay 2010: 271 points\nJune 2010: 366 points\nJuly 2010: 386 points\nAugust 2010: 380 points\nSeptember 2010: 403 points\nOctober 2010: 357 points\nNovember 2010: 396 points\nDecember 2010: 372 points\nJanuary 2011: 334 points\nFebruary 2011: 311 points\nMarch 2011: 460 points\nApril 2011: 359 points\nMay 2011: 374 points\nJune 2011: 348 points\nJuly 2011: 274 points\nAugust 2011: 370 points\nSeptember 2011: 453 points\nOctober 2011: 510 points\nNovember 2011: 451 points\nDecember 2011: 499 points\nJanuary 2012: 428 points\nFebruary 2012: 473 points\nMarch 2012: 451 points\nApril 2012: 470 points\nMay 2012: 455 points\nJune 2012: 496 points\nJuly 2012: 600 points\nAugust 2012: 573 points\nSeptember 2012: 547 points\nOctober 2012: 551 points\nNovember 2012: 578 points\nDecember 2012: 552 points\nJanuary 2013: 522 points\nFebruary 2013: 470 points\nMarch 2013: 454 points\nApril 2013: 440 points\nMay 2013: 503 points\nJune 2013: 513 points\nJuly 2013: 495 points\nAugust 2013: 583 points\nSeptember 2013: 698 points\nOctober 2013: 567 points\nNovember 2013: 453 points\nDecember 2013: 536 points\nJanuary 2014: 517 points\nFebruary 2014: 442 points\nMarch 2014: 527 points\nApril 2014: 649 points\nMay 2014: 641 points\nJune 2014: 682 points\nJuly 2014: 650 points\nAugust 2014: 645 points\nSeptember 2014: 495 points\nOctober 2014: 703 points\nNovember 2014: 566 points\nDecember 2014: 584 points\nJanuary 2015: 606 points\nFebruary 2015: 550 points\nMarch 2015: 626 points\nApril 2015: 728 points\nMay 2015: 825 points\nJune 2015: 716 points\nJuly 2015: 633 points\nAugust 2015: 628 points\nSeptember 2015: 627 points\nOctober 2015: 709 points\nNovember 2015: 638 points\nDecember 2015: 649 points\nJanuary 2016: 565 points\nFebruary 2016: 543 points\nMarch 2016: 508 points\nApril 2016: 511 points\nMay 2016: 493 points\nJune 2016: 477 points\nJuly 2016: 531 points\nAugust 2016: 562 points\nSeptember 2016: 482 points\nOctober 2016: 602 points\nNovember 2016: 586 points\nDecember 2016: 557 points\nJanuary 2017: 484 points\nFebruary 2017: 507 points\nMarch 2017: 571 points\nApril 2017: 547 points\nMay 2017: 462 points\nJune 2017: 461 points\nJuly 2017: 496 points\nAugust 2017: 456 points\nSeptember 2017: 434 points\nOctober 2017: 580 points\nNovember 2017: 318 points\nDecember 2017: 389 points\nJanuary 2018: 773 points\nFebruary 2018: 677 points\nMarch 2018: 749 points\nApril 2018: 740 points\nMay 2018: 524 points\nJune 2018: 471 points\nJuly 2018: 476 points\nAugust 2018: 430 points\nSeptember 2018: 438 points\nOctober 2018: 484 points\nNovember 2018: 443 points\nDecember 2018: 455 points\nJanuary 2019: 411 points\nFebruary 2019: 397 points\nMarch 2019: 405 points\nApril 2019: 436 points\nMay 2019: 437 points\nJune 2019: 448 points\nJuly 2019: 448 points\nAugust 2019: 419 points\nSeptember 2019: 471 points\nOctober 2019: 454 points\nNovember 2019: 481 points\nDecember 2019: 464 points\nJanuary 2020: 477 points\nFebruary 2020: 473 points\nMarch 2020: 511 points\nApril 2020: 521 points\nMay 2020: 602 points\nJune 2020: 669 points\nJuly 2020: 812 points\nAugust 2020: 651 points\nSeptember 2020: 526 points\nOctober 2020: 664 points\nNovember 2020: 744 points\nDecember 2020: 763 points\nJanuary 2021: 752 points\nFebruary 2021: 623 points\nMarch 2021: 591 points\nApril 2021: 567 points\nMay 2021: 666 points\nJune 2021: 600 points\nJuly 2021: 658 points\nAugust 2021: 661 points\nSeptember 2021: 607 points\nOctober 2021: 767 points\nNovember 2021: 645 points\nDecember 2021: 701 points\nJanuary 2022: 694 points\nFebruary 2022: 723 points\nMarch 2022: 643 points\nApril 2022: 590 points\nMay 2022: 582 points\nJune 2022: 636 points\nJuly 2022: 675 points\nAugust 2022: 692 points\nSeptember 2022: 730 points\nOctober 2022: 738 points\nNovember 2022: 700 points\nDecember 2022: 677 points\nJanuary 2023: 656 points\nFebruary 2023: 646 points\nMarch 2023: 730 points\nApril 2023: 737 points\nMay 2023: 831 points\nJune 2023: 755 points\nJuly 2023: 916 points\nAugust 2023: 770 points\nSeptember 2023: 770 points\nOctober 2023: 713 points\nNovember 2023: 667 points\nDecember 2023: 610 points\nJanuary 2024: 698 points\nFebruary 2024: 675 points\nMarch 2024: 592 points\nApril 2024: 519 points\nMay 2024: 565 points\nJune 2024: 616 points\nJuly 2024: 738 points\nAugust 2024: 622 points\nSeptember 2024: 586 points\nOctober 2024: 524 points\nNovember 2024: 427 points\nDecember 2024: 465 points\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\nfrom bokeh.io import output_notebook, show\nfrom bokeh.layouts import column\nfrom bokeh.models import Select, Slope, Label, CustomJS, HoverTool\nfrom bokeh.plotting import figure, ColumnDataSource\nimport numpy as np\nimport pandas as pd\n\n# Configure Bokeh to load silently\noutput_notebook(hide_banner=True)\n\n# Load and prepare your crime data\ndf = pd.read_csv(\"C:/NoterDTU/6_semester/Social_data/website_2/merged_data.csv\")\n\n# Define focus crimes\nfocuscrimes = {\n    'WEAPON LAWS', 'PROSTITUTION', 'ROBBERY', 'BURGLARY', 'ASSAULT', \n    'DRUG/NARCOTIC', 'LARCENY/THEFT', 'VANDALISM', 'VEHICLE THEFT', 'STOLEN PROPERTY'\n}\n\n# Filter and process data\ndf_focus = df[df['Category'].isin(focuscrimes)]\ndf_focus_grouped = df_focus.groupby(['Year', 'Month', 'Category']).size().reset_index(name='Crime_Count')\ndf_focus_grouped['Date'] = pd.to_datetime(df_focus_grouped['Month'] + ' ' + df_focus_grouped['Year'].astype(str), errors='coerce')\ndf_focus_grouped = df_focus_grouped.dropna()\n\n# Extract month and year for hover tool\ndf_focus_grouped['Month_Year'] = df_focus_grouped['Date'].dt.strftime('%b %Y')\n\n# Pivot the data\ndf_pivot = df_focus_grouped.pivot_table(index=['Date', 'Month_Year'], columns='Category', values='Crime_Count', fill_value=0)\ndf_pivot['Total Crimes'] = df_pivot.sum(axis=1)\ndf_pivot.reset_index(inplace=True)\n\n# Prepare plotting data\nnumeric_cols = [col for col in df_pivot.columns if col not in ['Date', 'Month_Year']]\ndf_plot = df_pivot[numeric_cols]\n\n# Set initial variables\nx_init = numeric_cols[8]\ny_init = numeric_cols[1]\nx_data = df_plot[x_init].values\ny_data = df_plot[y_init].values\n\n# Calculate initial regression\nn = len(x_data)\nx_sum, y_sum, xy_sum, x2_sum, y2_sum = x_data.sum(), y_data.sum(), (x_data*y_data).sum(), (x_data**2).sum(), (y_data**2).sum()\nslope_val = (n * xy_sum - x_sum * y_sum) / (n * x2_sum - x_sum * x_sum)\nintercept = (y_sum - slope_val * x_sum) / n\nr_value = (n * xy_sum - x_sum * y_sum) / np.sqrt((n * x2_sum - x_sum * x_sum) * (n * y2_sum - y_sum * y_sum))\nr_squared = r_value ** 2\n\n# Create ColumnDataSource with Month_Year for hover tool\nsource = ColumnDataSource(df_pivot)\n\n# Create figure with initial axis labels\nplot = figure(\n    title=\"Crime Data Correlation Analysis\", \n    x_axis_label=\"Number of incidents for X-axis crime type (month,year)\",\n    y_axis_label=\"Number of incidents for Y-axis crime type (month,year)\",\n    tools=\"pan,wheel_zoom,box_zoom,reset\",\n    width=750, \n    height=550,\n    background_fill_color=\"#f5f5f5\",\n    toolbar_location=\"above\"\n)\n\n# Format plot appearance\nplot.title.text_font_size = '16pt'\nplot.xaxis.axis_label_text_font_size = \"12pt\"\nplot.yaxis.axis_label_text_font_size = \"12pt\"\nplot.grid.grid_line_alpha = 0.3\n\n# Add only the month-year hover tool\nhover = HoverTool(\n    tooltips=[\n        (\"Time Period\", \"@Month_Year\"),\n        (x_init, f\"@{{{x_init}}}\"),\n        (y_init, f\"@{{{y_init}}}\"),\n        (\"Total Crimes\", \"@{Total Crimes}\")\n    ],\n    mode='mouse'\n)\nplot.add_tools(hover)\n\n# Initial scatter plot\nscatter = plot.scatter(x=x_init, y=y_init, source=source, size=10,\n                      color=\"navy\", alpha=0.7, line_color=\"white\")\n\n# Dropdown widgets\nx_axis = Select(title=\"X-Axis Crime Type:\", value=x_init,\n               options=sorted(numeric_cols), width=250)\ny_axis = Select(title=\"Y-Axis Crime Type:\", value=y_init,\n               options=sorted(numeric_cols), width=250)\n\n# Regression line\nslope = Slope(gradient=slope_val, y_intercept=intercept, \n             line_color='red', line_dash='dashed', line_width=2.5)\nplot.add_layout(slope)\n\n# R² label\nr_squared_label = Label(x=70, y=10, x_units='screen', y_units='screen',\n                       text=f\"R² = {r_squared:.3f}\", text_font_size='13px',\n                       text_color='red', background_fill_color='white',\n                       background_fill_alpha=0.8)\nplot.add_layout(r_squared_label)\n\n# JavaScript callback with axis label updates\ncallback = CustomJS(args=dict(\n    source=source,\n    scatter=scatter,\n    slope=slope,\n    r_squared_label=r_squared_label,\n    plot=plot,\n    x_axis=x_axis,\n    y_axis=y_axis\n), code=\"\"\"\n    const x = x_axis.value;\n    const y = y_axis.value;\n    const x_data = source.data[x];\n    const y_data = source.data[y];\n    \n    // Calculate statistics\n    let x_sum = 0, y_sum = 0, xy_sum = 0, x2_sum = 0, y2_sum = 0;\n    const n = x_data.length;\n    \n    for (let i = 0; i &lt; n; i++) {\n        x_sum += x_data[i];\n        y_sum += y_data[i];\n        xy_sum += x_data[i] * y_data[i];\n        x2_sum += x_data[i] * x_data[i];\n        y2_sum += y_data[i] * y_data[i];\n    }\n    \n    // Calculate regression parameters\n    const slope_val = (n * xy_sum - x_sum * y_sum) / (n * x2_sum - x_sum * x_sum);\n    const intercept = (y_sum - slope_val * x_sum) / n;\n    const r_value = (n * xy_sum - x_sum * y_sum) / \n                   Math.sqrt((n * x2_sum - x_sum * x_sum) * (n * y2_sum - y_sum * y_sum));\n    const r_squared = r_value * r_value;\n    \n    // Update plot elements\n    scatter.glyph.x = {field: x};\n    scatter.glyph.y = {field: y};\n    slope.gradient = slope_val;\n    slope.y_intercept = intercept;\n    r_squared_label.text = `R² = ${r_squared.toFixed(3)}`;\n    \n    // Update axis labels\n    plot.xaxis.axis_label = `${x} (Count)`;\n    plot.yaxis.axis_label = `${y} (Count)`;\n\"\"\")\n\n# Connect callbacks\nx_axis.js_on_change('value', callback)\ny_axis.js_on_change('value', callback)\n\n# Layout\nlayout = column(\n    column(x_axis, y_axis, width=300),\n    plot\n)\n\n# Show the plot\nshow(layout)\n#yes"
  },
  {
    "objectID": "hw2.html",
    "href": "hw2.html",
    "title": "Assignment unga bunga",
    "section": "",
    "text": "Code\nimport pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\ndata=pd.read_csv(\"C:/NoterDTU/6_semester/Social_data/website_2/s224394.github.io/merged_data.csv\")\ncrimes = data[['Category', 'Year']]\ncrimes = crimes[(crimes['Category']=='VEHICLE THEFT') & (crimes['Year']!=2025)  ]\ncrime_counts = crimes[\"Year\"].value_counts().sort_index()\ncrime_counts.plot(kind=\"bar\",color=\"indigo\",edgecolor=\"black\")\nplt.ylabel(\"Number of incidents\")\nplt.xlabel(\"Year\")\nplt.title(\"Number of Vehicle thefts per year (2003-2025)\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nimport pandas as pd\nimport folium\nfrom folium.plugins import HeatMapWithTime\nfrom IPython.display import display\n\n# Load data\ndf = pd.read_csv(\"C:/NoterDTU/6_semester/Social_data/website_2/s224394.github.io/merged_data.csv\")\n\n# Filter for vehicle thefts between 2003-2007\ndf_filtered = df[(df['Category'] == 'VEHICLE THEFT') & \n                 (df['Year'].between(2003, 2024))].copy()\n\n# Extract relevant columns and drop NA\ndf_filtered = df_filtered[['Latitude', 'Longitude', 'Month', 'Year']].dropna()\n\n# Check for valid coordinates\nvalid_coords = df_filtered[\n    (df_filtered['Latitude'].between(-90, 90)) & \n    (df_filtered['Longitude'].between(-180, 180))\n]\n\n# Define month mapping and order\nmonth_mapping = {\n    \"January\": 1, \"February\": 2, \"March\": 3, \"April\": 4, \n    \"May\": 5, \"June\": 6, \"July\": 7, \"August\": 8, \n    \"September\": 9, \"October\": 10, \"November\": 11, \"December\": 12\n}\nmonth_names = list(month_mapping.keys())\n\n# Create numerical month column\ndf_filtered['MonthNum'] = df_filtered['Month'].map(month_mapping)\n\n# Sort by year and month\ndf_filtered = df_filtered.sort_values(['Year', 'MonthNum'])\n\n# Prepare heat data and time index\nheat_data = []\ntime_index = []\n\nfor year in range(2003, 2025):\n    for month_num in range(1, 13):\n        month_data = df_filtered[\n            (df_filtered['Year'] == year) & \n            (df_filtered['MonthNum'] == month_num)\n        ]\n        coords = month_data[['Latitude', 'Longitude']].values.tolist()\n        heat_data.append(coords)\n        time_index.append(f\"{month_names[month_num-1]} {year}\")\n        \n\n# Only create map if we have data\n\n# Create base map\nbase_map = folium.Map(location=[37.77919, -122.41914], zoom_start=12.5)\n\n# Add heatmap with time\nHeatMapWithTime(\n    heat_data,\n    index=time_index,  # Time labels showing month and year\n    auto_play=0,\n    max_opacity=0.5,\n    radius=13,\n    min_opacity=0.1,\n    gradient={0.2: 'blue', 0.4: 'lime', 0.6: 'orange', 0.8: 'red'},\n    display_index=True,\n    use_local_extrema=False, \n    name=\"Vehicle Thefts\",\n    blur=1\n).add_to(base_map)\n\n# Display map\ndisplay(base_map)\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\n\nCode\nfrom bokeh.io import output_notebook, show\nfrom bokeh.layouts import column\nfrom bokeh.models import Select, Slope, Label, CustomJS, HoverTool\nfrom bokeh.plotting import figure, ColumnDataSource\nimport numpy as np\nimport pandas as pd\n\n# Configure Bokeh to load silently\noutput_notebook(hide_banner=True)\n\n# Load and prepare your crime data\ndf =pd.read_csv(\"C:/NoterDTU/6_semester/Social_data/website_2/s224394.github.io/merged_data.csv\")\n\n# Define focus crimes\nfocuscrimes = {\n    'WEAPON LAWS', 'PROSTITUTION', 'ROBBERY', 'BURGLARY', 'ASSAULT', \n    'DRUG/NARCOTIC', 'LARCENY/THEFT', 'VANDALISM', 'VEHICLE THEFT', 'STOLEN PROPERTY'\n}\n\n# Filter and process data\ndf_focus = df[df['Category'].isin(focuscrimes)]\ndf_focus_grouped = df_focus.groupby(['Year', 'Month', 'Category']).size().reset_index(name='Crime_Count')\ndf_focus_grouped['Date'] = pd.to_datetime(df_focus_grouped['Month'] + ' ' + df_focus_grouped['Year'].astype(str), errors='coerce')\ndf_focus_grouped = df_focus_grouped.dropna()\n\n# Extract month and year for hover tool\ndf_focus_grouped['Month_Year'] = df_focus_grouped['Date'].dt.strftime('%b %Y')\n\n# Pivot the data\ndf_pivot = df_focus_grouped.pivot_table(index=['Date', 'Month_Year'], columns='Category', values='Crime_Count', fill_value=0)\ndf_pivot['Total Crimes'] = df_pivot.sum(axis=1)\ndf_pivot.reset_index(inplace=True)\n\n# Prepare plotting data\nnumeric_cols = [col for col in df_pivot.columns if col not in ['Date', 'Month_Year']]\ndf_plot = df_pivot[numeric_cols]\n\n# Set initial variables\nx_init = numeric_cols[8]\ny_init = numeric_cols[1]\nx_data = df_plot[x_init].values\ny_data = df_plot[y_init].values\n\n# Calculate initial regression\nn = len(x_data)\nx_sum, y_sum, xy_sum, x2_sum, y2_sum = x_data.sum(), y_data.sum(), (x_data*y_data).sum(), (x_data**2).sum(), (y_data**2).sum()\nslope_val = (n * xy_sum - x_sum * y_sum) / (n * x2_sum - x_sum * x_sum)\nintercept = (y_sum - slope_val * x_sum) / n\nr_value = (n * xy_sum - x_sum * y_sum) / np.sqrt((n * x2_sum - x_sum * x_sum) * (n * y2_sum - y_sum * y_sum))\nr_squared = r_value ** 2\n\n# Create ColumnDataSource with Month_Year for hover tool\nsource = ColumnDataSource(df_pivot)\n\n# Create figure with initial axis labels\nplot = figure(\n    title=\"Crime Data Correlation Analysis\", \n    x_axis_label=\"Number of incidents for X-axis crime type (month,year)\",\n    y_axis_label=\"Number of incidents for Y-axis crime type (month,year)\",\n    tools=\"pan,wheel_zoom,box_zoom,reset\",\n    width=750, \n    height=550,\n    background_fill_color=\"#f5f5f5\",\n    toolbar_location=\"above\"\n)\n\n# Format plot appearance\nplot.title.text_font_size = '16pt'\nplot.xaxis.axis_label_text_font_size = \"12pt\"\nplot.yaxis.axis_label_text_font_size = \"12pt\"\nplot.grid.grid_line_alpha = 0.3\n\n# Add only the month-year hover tool\nhover = HoverTool(\n    tooltips=[\n        (\"Time Period\", \"@Month_Year\"),\n        (x_init, f\"@{{{x_init}}}\"),\n        (y_init, f\"@{{{y_init}}}\"),\n        (\"Total Crimes\", \"@{Total Crimes}\")\n    ],\n    mode='mouse'\n)\nplot.add_tools(hover)\n\n# Initial scatter plot\nscatter = plot.scatter(x=x_init, y=y_init, source=source, size=10,\n                      color=\"navy\", alpha=0.7, line_color=\"white\")\n\n# Dropdown widgets\nx_axis = Select(title=\"X-Axis Crime Type:\", value=x_init,\n               options=sorted(numeric_cols), width=250)\ny_axis = Select(title=\"Y-Axis Crime Type:\", value=y_init,\n               options=sorted(numeric_cols), width=250)\n\n# Regression line\nslope = Slope(gradient=slope_val, y_intercept=intercept, \n             line_color='red', line_dash='dashed', line_width=2.5)\nplot.add_layout(slope)\n\n# R² label\nr_squared_label = Label(x=70, y=10, x_units='screen', y_units='screen',\n                       text=f\"R² = {r_squared:.3f}\", text_font_size='13px',\n                       text_color='red', background_fill_color='white',\n                       background_fill_alpha=0.8)\nplot.add_layout(r_squared_label)\n\n# JavaScript callback with axis label updates\ncallback = CustomJS(args=dict(\n    source=source,\n    scatter=scatter,\n    slope=slope,\n    r_squared_label=r_squared_label,\n    plot=plot,\n    x_axis=x_axis,\n    y_axis=y_axis\n), code=\"\"\"\n    const x = x_axis.value;\n    const y = y_axis.value;\n    const x_data = source.data[x];\n    const y_data = source.data[y];\n    \n    // Calculate statistics\n    let x_sum = 0, y_sum = 0, xy_sum = 0, x2_sum = 0, y2_sum = 0;\n    const n = x_data.length;\n    \n    for (let i = 0; i &lt; n; i++) {\n        x_sum += x_data[i];\n        y_sum += y_data[i];\n        xy_sum += x_data[i] * y_data[i];\n        x2_sum += x_data[i] * x_data[i];\n        y2_sum += y_data[i] * y_data[i];\n    }\n    \n    // Calculate regression parameters\n    const slope_val = (n * xy_sum - x_sum * y_sum) / (n * x2_sum - x_sum * x_sum);\n    const intercept = (y_sum - slope_val * x_sum) / n;\n    const r_value = (n * xy_sum - x_sum * y_sum) / \n                   Math.sqrt((n * x2_sum - x_sum * x_sum) * (n * y2_sum - y_sum * y_sum));\n    const r_squared = r_value * r_value;\n    \n    // Update plot elements\n    scatter.glyph.x = {field: x};\n    scatter.glyph.y = {field: y};\n    slope.gradient = slope_val;\n    slope.y_intercept = intercept;\n    r_squared_label.text = `R² = ${r_squared.toFixed(3)}`;\n    \n    // Update axis labels\n    plot.xaxis.axis_label = `${x} (Count)`;\n    plot.yaxis.axis_label = `${y} (Count)`;\n\"\"\")\n\n# Connect callbacks\nx_axis.js_on_change('value', callback)\ny_axis.js_on_change('value', callback)\n\n# Layout\nlayout = column(\n    column(x_axis, y_axis, width=300),\n    plot\n)\n\n# Show the plot\nshow(layout)\n\n\n\n  \n\n\n\n\n\nCode\n2+2\n\n\n4"
  },
  {
    "objectID": "hello.html",
    "href": "hello.html",
    "title": "Quarto Basics",
    "section": "",
    "text": "For a demonstration of a line plot on a polar axis, see Figure 1.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 1, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1: A line plot on a polar axis\n\n\n\n\n\nHello? is this thing working???"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Looking at Vehicle thefts from 2003-2024 in",
    "section": "",
    "text": "Since the year 2003 the police department of san francisco has been reporting crime statistics. All these data are available to the public and are therefore relevant for data analysis. Of particular interest for data analysis is the different crime types, the time of incident (both date but also time of day down to the minute) but also the coordinates of the incident (given in latitude/longitude). From this data its possible to look at temporal and spatial trends of different crimes over the last 20+ years. The different categories of crimes include vehicle theft, vandalism, robbery, prostitution and many more.\nWe have chosen to look at the trend of vehicle thefts since the trend seems “unique” compared to the other types of crimes. This will be shown in the following plots."
  },
  {
    "objectID": "index.html#the-data",
    "href": "index.html#the-data",
    "title": "Looking at Vehicle thefts from 2003-2024 in",
    "section": "",
    "text": "Since the year 2003 the police department of san francisco has been reporting crime data. Of particular intererest for analysis is the different crime types, the time of incident (both date but also time of day down to the minute) but also the coordinates of the incident (given in latitude/longitude). From this data its possible to look at temporal and spatial trends of different crimes over the last 20+ years. The different categoris of crimes include Vehicle theft, vandalism, robbery, prostiution and many more. I have choosen to look at the trends of vehicle thefts since the trend in many ways are unique compared to the other types of crimes, but i will go more into detail later."
  },
  {
    "objectID": "index.html#the-temporal-trend-of-vehicle-thefts",
    "href": "index.html#the-temporal-trend-of-vehicle-thefts",
    "title": "Looking at Vehicle thefts from 2003-2024 in",
    "section": "The temporal trend of vehicle thefts",
    "text": "The temporal trend of vehicle thefts\nThe first relevant plot is the number of incidents of vehicle theft per year. We ignore 2025 since the we do not have data for that entire year.\n\n\nCode\nimport pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\ndata=pd.read_csv(\"C:/NoterDTU/6_semester/Social_data/website_2/s224394.github.io/merged_data.csv\")\ncrimes = data[['Category', 'Year']]\ncrimes = crimes[(crimes['Category']=='VEHICLE THEFT') & (crimes['Year']!=2025)  ]\ncrime_counts = crimes[\"Year\"].value_counts().sort_index()\nplt.figure().set_figwidth(7.4)\ncrime_counts.plot(kind=\"bar\",color=\"indigo\",edgecolor=\"black\")\nax=plt.gca()\n\nax.set_facecolor(\"#f5f5f5\")\nplt.ylabel(\"Number of incidents\")\nplt.xlabel(\"Year\")\nplt.title(\"Number of Vehicle thefts per year (2003-2024)\")\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1: The plot shows the number of reported incidents of “Vehicle Theft” by the SFPD for every year 2003-2024. There is a 60% percent drop from 2005 to 2006 which might suggest that somethinge was actively done in order to reduce the number of vehicle thefts.\n\n\n\n\n\nOne thing that seems unique is the sudden drop from 2005 to 2006 and onwards. In 2005 the numbers peak at around 17.500 vehicle thefts while the next year it drops by around 10.000 and remains in that range going forward. This is approximately 60% of the crimes that just stopped happening in one year. One would suspect that the police force might have increased the resources for fighting vehicle theft. Another explanation might be that cars became harder to steal because of increased security measures.\nThe news article “Car Thefts Decrease Statewide” by east bay times from 2007 (Staff 2007) talks about the general trend for vehicle theft being on the decline. The reason behind this trend is both the fact that more and more vehicle have implemented alarms, key-coding systems etc. But also there has also been set up 16 auto-theft task forces. There were also an increase in the use of so called “bait-cars”. The way “bait-cars” work is by including a hidden gps in the car and making it intentionally easy to steal. The cars are then used to track down the drivers. Since the car thieves often are responsible for stealing more than one car. Catching one criminal might decrease the number of cars being stolen significantly. In 2006 they made 357 arrest with the use of bait-cars. Which might have severely impacted the amount of cars stolen.\nWe also see an upward trend in vehicle thefts after post-2010 and post-2020. One theory as to why this is the case could be related to the two economic crisis. The 2008 financial crisis and the beginning of the covid-19 pandemic in 2020 might have pushed more people into poverty. Which in turn then makes it so more people commits crime in order to survive."
  },
  {
    "objectID": "index.html#the-spatial-trends",
    "href": "index.html#the-spatial-trends",
    "title": "Looking at Vehicle thefts from 2003-2024 in",
    "section": "The spatial trends",
    "text": "The spatial trends\nOne thing one might suspect could explain the sudden drop is if there suddenly where a focus from the police deparment on a specific area. As previously mentioned they have the data for where the different crimes are happening and one would then think that they then priotize forces in these specific areas. In order to look at the we plot a time series of where the incidents of vehecle theft is happening for a given month and try to see if there is any difference.\n\n\nCode\nimport folium\nfrom folium.plugins import HeatMapWithTime\nfrom IPython.display import display\n\n# Load data\ndf = pd.read_csv(\"C:/NoterDTU/6_semester/Social_data/website_2/s224394.github.io/merged_data.csv\")\n\n# Filter for vehicle thefts between 2003-2007\ndf_filtered = df[(df['Category'] == 'VEHICLE THEFT') & \n                 (df['Year'].between(2003, 2024))].copy()\n\n# Extract relevant columns and drop NA\ndf_filtered = df_filtered[['Latitude', 'Longitude', 'Month', 'Year']].dropna()\n\n# Check for valid coordinates\nvalid_coords = df_filtered[\n    (df_filtered['Latitude'].between(-90, 90)) & \n    (df_filtered['Longitude'].between(-180, 180))\n]\n\n# Define month mapping and order\nmonth_mapping = {\n    \"January\": 1, \"February\": 2, \"March\": 3, \"April\": 4, \n    \"May\": 5, \"June\": 6, \"July\": 7, \"August\": 8, \n    \"September\": 9, \"October\": 10, \"November\": 11, \"December\": 12\n}\nmonth_names = list(month_mapping.keys())\n\n# Create numerical month column\ndf_filtered['MonthNum'] = df_filtered['Month'].map(month_mapping)\n\n# Sort by year and month\ndf_filtered = df_filtered.sort_values(['Year', 'MonthNum'])\n\n# Prepare heat data and time index\nheat_data = []\ntime_index = []\n\nfor year in range(2003, 2025):\n    for month_num in range(1, 13):\n        month_data = df_filtered[\n            (df_filtered['Year'] == year) & \n            (df_filtered['MonthNum'] == month_num)\n        ]\n        coords = month_data[['Latitude', 'Longitude']].values.tolist()\n        heat_data.append(coords)\n        time_index.append(f\"{month_names[month_num-1]} {year}\")\n        \n\n# Only create map if we have data\n\n# Create base map\nbase_map = folium.Map(location=[37.75800, -122.41914], zoom_start=11.5,zoom_control=0,scrollWheelZoom=False,dragging=0)\n\n# Add heatmap with time\nHeatMapWithTime(\n    heat_data,\n    index=time_index,  # Time labels showing month and year\n    auto_play=0,\n    max_opacity=0.5,\n    radius=11,\n    min_opacity=0.1,\n    gradient={0.2: 'blue', 0.4: 'lime', 0.6: 'orange', 0.8: 'red'},\n    display_index=True,\n    use_local_extrema=1, \n    name=\"Vehicle Thefts\",\n    blur=1\n).add_to(base_map)\n\n# Display map\ndisplay(base_map)\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\nFrom the heatmap its clear that a lot of the incidents happen in the north-eastern/eastern part of san francisco. And that trend does not change as teh years go by. But its clear that there is fewer crimes compared to 2003-2005 and the years after since the point of the heat map are more spread out. 😎 Hello is this thing working?\nAfter 2006 the number of incidents are generally low compared to there is still two times an upward trend. After 2010 and after 2019. Might inital guess would be that they are both related to the econimic crisis that happende around there. The 2009 economic crahs and the begenning of the corona pandemic both made it so more people were poor and therefore needed to steal.\nLast thing that could be interesting to look at is if the trends in data are unique to car theft or if the over all trend of crime is the “same” as with the car theft."
  },
  {
    "objectID": "index.html#correlation-between-crimes",
    "href": "index.html#correlation-between-crimes",
    "title": "Looking at Vehicle thefts from 2003-2024 in",
    "section": "Correlation between crimes",
    "text": "Correlation between crimes\nIn order to determine how unique the trend of vehicle theft are it makes sense to compare the data to the other crimes reported. We choose to look at the the number of incidents per month for a given crime. Afterwards we see how correlated the data for two crimes are. The correlation coefficient for the given plot are also calculated as to give a statistical measure of how correlated the data are. In the plot its possible to choose which crime categories to compare. If you hover over one of the points you get the month and year of the data and also the number of incidents.\n\n\nCode\nfrom bokeh.io import output_notebook, show\nfrom bokeh.layouts import column, row\nfrom bokeh.models import Select, Slope, Label, CustomJS, HoverTool\nfrom bokeh.plotting import figure, ColumnDataSource\n\n# Configure Bokeh to load silently\noutput_notebook(hide_banner=True)\n\n# Define focus crimes\nfocuscrimes = {\n    'WEAPON LAWS', 'PROSTITUTION', 'ROBBERY', 'BURGLARY', 'ASSAULT', \n    'DRUG/NARCOTIC', 'LARCENY/THEFT', 'VANDALISM', 'VEHICLE THEFT', 'STOLEN PROPERTY'\n}\n\n\n# Load data\ndf = pd.read_csv(\"C:/NoterDTU/6_semester/Social_data/website_2/s224394.github.io/merged_data.csv\")\n\n# Filter and process data\ndf_focus = df[df['Category'].isin(focuscrimes)]\ndf_focus_grouped = df_focus.groupby(['Year', 'Month', 'Category']).size().reset_index(name='Crime_Count')\ndf_focus_grouped['Date'] = pd.to_datetime(df_focus_grouped['Month'] + ' ' + df_focus_grouped['Year'].astype(str), errors='coerce')\ndf_focus_grouped = df_focus_grouped.dropna()\n\n# Extract month and year for hover tool\ndf_focus_grouped['Month_Year'] = df_focus_grouped['Date'].dt.strftime('%b %Y')\n\n# Pivot the data\ndf_pivot = df_focus_grouped.pivot_table(index=['Date', 'Month_Year'], columns='Category', values='Crime_Count', fill_value=0)\ndf_pivot['Total Crimes'] = df_pivot.sum(axis=1)\ndf_pivot.reset_index(inplace=True)\n\n# Prepare plotting data\nnumeric_cols = [col for col in df_pivot.columns if col not in ['Date', 'Month_Year']]\ndf_plot = df_pivot[numeric_cols]\n\n# Set initial variables\nx_init = numeric_cols[8]\ny_init = numeric_cols[1]\nx_data = df_plot[x_init].values\ny_data = df_plot[y_init].values\n\n# Calculate initial regression\nn = len(x_data)\nx_sum, y_sum, xy_sum, x2_sum, y2_sum = x_data.sum(), y_data.sum(), (x_data*y_data).sum(), (x_data**2).sum(), (y_data**2).sum()\nslope_val = (n * xy_sum - x_sum * y_sum) / (n * x2_sum - x_sum * x_sum)\nintercept = (y_sum - slope_val * x_sum) / n\nr_value = (n * xy_sum - x_sum * y_sum) / np.sqrt((n * x2_sum - x_sum * x_sum) * (n * y2_sum - y_sum * y_sum))\nr_squared = r_value ** 2\n\n# Create ColumnDataSource with Month_Year for hover tool\nsource = ColumnDataSource(df_pivot)\n\n# Create figure with initial axis labels\nplot = figure(\n    title=\"Crime Data Correlation Analysis\", \n    x_axis_label=\"Number of incidents for X-axis crime type (month,year)\",\n    y_axis_label=\"Number of incidents for Y-axis crime type (month,year)\",\n    tools=\"pan,wheel_zoom,box_zoom,reset\",\n    width=750, \n    height=550,\n    background_fill_color=\"#f5f5f5\",\n    toolbar_location=\"above\"\n)\n\n# Format plot appearance\nplot.title.text_font_size = '16pt'\nplot.xaxis.axis_label_text_font_size = \"12pt\"\nplot.yaxis.axis_label_text_font_size = \"12pt\"\nplot.grid.grid_line_alpha = 0.3\n\n# Add only the month-year hover tool\nhover = HoverTool(\n    tooltips=[\n        (\"Time Period\", \"@Month_Year\"),\n        (x_init, f\"@{{{x_init}}}\"),\n        (y_init, f\"@{{{y_init}}}\"),\n        (\"Total Crimes\", \"@{Total Crimes}\")\n    ],\n    mode='mouse'\n)\nplot.add_tools(hover)\n\n# Initial scatter plot\nscatter = plot.scatter(x=x_init, y=y_init, source=source, size=10,\n                      color=\"indigo\", alpha=0.7, line_color=\"white\")\n\n# Dropdown widgets\nx_axis = Select(title=\"X-Axis Crime Type:\", value=x_init,\n               options=sorted(numeric_cols), width=250)\ny_axis = Select(title=\"Y-Axis Crime Type:\", value=y_init,\n               options=sorted(numeric_cols), width=250)\n\n# Regression line\nslope = Slope(gradient=slope_val, y_intercept=intercept, \n             line_color='red', line_dash='dashed', line_width=2.5)\nplot.add_layout(slope)\n\n# R² label\nr_squared_label = Label(x=70, y=10, x_units='screen', y_units='screen',\n                       text=f\"R² = {r_squared:.3f}\", text_font_size='13px',\n                       text_color='red', background_fill_color='white',\n                       background_fill_alpha=0.8)\nplot.add_layout(r_squared_label)\n\n# JavaScript callback with axis label updates\ncallback = CustomJS(args=dict(\n    source=source,\n    scatter=scatter,\n    slope=slope,\n    r_squared_label=r_squared_label,\n    plot=plot,\n    x_axis=x_axis,\n    y_axis=y_axis\n), code=\"\"\"\n    const x = x_axis.value;\n    const y = y_axis.value;\n    const x_data = source.data[x];\n    const y_data = source.data[y];\n    \n    // Calculate statistics\n    let x_sum = 0, y_sum = 0, xy_sum = 0, x2_sum = 0, y2_sum = 0;\n    const n = x_data.length;\n    \n    for (let i = 0; i &lt; n; i++) {\n        x_sum += x_data[i];\n        y_sum += y_data[i];\n        xy_sum += x_data[i] * y_data[i];\n        x2_sum += x_data[i] * x_data[i];\n        y2_sum += y_data[i] * y_data[i];\n    }\n    \n    // Calculate regression parameters\n    const slope_val = (n * xy_sum - x_sum * y_sum) / (n * x2_sum - x_sum * x_sum);\n    const intercept = (y_sum - slope_val * x_sum) / n;\n    const r_value = (n * xy_sum - x_sum * y_sum) / \n                   Math.sqrt((n * x2_sum - x_sum * x_sum) * (n * y2_sum - y_sum * y_sum));\n    const r_squared = r_value * r_value;\n    \n    // Update plot elements\n    scatter.glyph.x = {field: x};\n    scatter.glyph.y = {field: y};\n    slope.gradient = slope_val;\n    slope.y_intercept = intercept;\n    r_squared_label.text = `R² = ${r_squared.toFixed(3)}`;\n    \n    // Update axis labels\n    plot.xaxis.axis_label = `${x} (Count)`;\n    plot.yaxis.axis_label = `${y} (Count)`;\n\"\"\")\n\n# Connect callbacks\nx_axis.js_on_change('value', callback)\ny_axis.js_on_change('value', callback)\n    \n# Layout\nlayout = column(\n    row(x_axis, y_axis, spacing=20),\n    plot\n)\n\n# Show the plot\nshow(layout)\n\n\n\n\n\n  \n\n\n\nFigure 3: This plot number of incidents for two choosen crimes for a given month and year as a scatterplot. The correlation is calculated and there has been calculated a linear fit. The correlation coefficient between vehicle theft and any other crimes close to zero in most cases. This is not always the case when comparing other types of crimes.\n\n\n\n\nComparing vehicle theft to the other crimes one sees that there is close to zero correlation between any of the crimes and vehicle theft. The reason behind this is probably the incidents of the years 2003-2005. In most of the plots comparing vehicle data the data from 2003-2005 is completely separate from the rest of the data. This suggest that the sudden drop of vehicle thefts are unique compared all the other crimes. The plots suggest that if we only only looked at the data post-2006 then the correlation would be much greater. One theory as to why this is the case is might be the focus an battling vehicle theft in 2006. Which lead to a 60% drop in crimes. Where as other crimes such as burglary and vandalism where not focused on. In order to fully determine if the behavior of vehicle theft are unique we also looked at the correlation between some of the other crimes. An example could be robbery and assault which are way more correlated (\\(r^2\\) value of 0.485) and generally if we compare most of the crimes with the total number of crimes, then they are fairly correlated. Examples being vandalism having \\(r^2=0.486\\) and larceny/theft having \\(r^2=0.700\\). Some of this might also be explained in larceny/theft and vandalism playing a bigger part of the crime incidents numbers. Not all types of crimes peak in the same months. But this once again suggest that vehicle theft massive drop where unique."
  },
  {
    "objectID": "index.html#san-francisco-police-department-crime-data",
    "href": "index.html#san-francisco-police-department-crime-data",
    "title": "Looking at Vehicle thefts from 2003-2024 in",
    "section": "",
    "text": "Since the year 2003 the police department of san francisco has been reporting crime statistics. All these data are available to the public and are therefore relevant for data analysis. Of particular interest for data analysis is the different crime types, the time of incident (both date but also time of day down to the minute) but also the coordinates of the incident (given in latitude/longitude). From this data its possible to look at temporal and spatial trends of different crimes over the last 20+ years. The different categories of crimes include vehicle theft, vandalism, robbery, prostitution and many more.\nWe have chosen to look at the trend of vehicle thefts since the trend seems “unique” compared to the other types of crimes. This will be shown in the following plots."
  },
  {
    "objectID": "index.html#the-spatial-trends-of-vehicle-theft",
    "href": "index.html#the-spatial-trends-of-vehicle-theft",
    "title": "Looking at Vehicle thefts from 2003-2024 in",
    "section": "The spatial trends of vehicle theft",
    "text": "The spatial trends of vehicle theft\nThe figure and the news article from before suggests that we might be able to see a decrease of crimes if we look at a heatmap of the crimes. One could suspect that the increase in auto-theft task forces might have forced the incidents to move location. In order to look into this we plot the spatial data for vehicle thefts as a heatmap. We look at the incidents for a given month starting january 2003 and going forward.\n\n\nCode\nimport folium\nfrom folium.plugins import HeatMapWithTime\nfrom IPython.display import display\n\n# Load data\ndf = pd.read_csv(\"C:/NoterDTU/6_semester/Social_data/website_2/s224394.github.io/merged_data.csv\")\n\n# Filter for vehicle thefts between 2003-2007\ndf_filtered = df[(df['Category'] == 'VEHICLE THEFT') & \n                 (df['Year'].between(2003, 2024))].copy()\n\n# Extract relevant columns and drop NA\ndf_filtered = df_filtered[['Latitude', 'Longitude', 'Month', 'Year']].dropna()\n\n# Check for valid coordinates\nvalid_coords = df_filtered[\n    (df_filtered['Latitude'].between(-90, 90)) & \n    (df_filtered['Longitude'].between(-180, 180))\n]\n\n# Define month mapping and order\nmonth_mapping = {\n    \"January\": 1, \"February\": 2, \"March\": 3, \"April\": 4, \n    \"May\": 5, \"June\": 6, \"July\": 7, \"August\": 8, \n    \"September\": 9, \"October\": 10, \"November\": 11, \"December\": 12\n}\nmonth_names = list(month_mapping.keys())\n\n# Create numerical month column\ndf_filtered['MonthNum'] = df_filtered['Month'].map(month_mapping)\n\n# Sort by year and month\ndf_filtered = df_filtered.sort_values(['Year', 'MonthNum'])\n\n# Prepare heat data and time index\nheat_data = []\ntime_index = []\n\nfor year in range(2003, 2025):\n    for month_num in range(1, 13):\n        month_data = df_filtered[\n            (df_filtered['Year'] == year) & \n            (df_filtered['MonthNum'] == month_num)\n        ]\n        coords = month_data[['Latitude', 'Longitude']].values.tolist()\n        heat_data.append(coords)\n        time_index.append(f\"{month_names[month_num-1]} {year}\")\n        \n\n# Only create map if we have data\n\n# Create base map\nbase_map = folium.Map(location=[37.75800, -122.41914], zoom_start=11.5,zoom_control=0,scrollWheelZoom=False,dragging=0)\n\n# Add heatmap with time\nHeatMapWithTime(\n    heat_data,\n    index=time_index,  # Time labels showing month and year\n    auto_play=0,\n    max_opacity=0.5,\n    radius=11,\n    min_opacity=0.1,\n    gradient={0.2: 'blue', 0.4: 'lime', 0.6: 'orange', 0.8: 'red'},\n    display_index=True,\n    use_local_extrema=1, \n    name=\"Vehicle Thefts\",\n    #position=\"bottomright\",\n    blur=1\n).add_to(base_map)\n\n# Display map\ndisplay(base_map)\n\n\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\nFigure 2: The plots shows a time series heatmap of the affected san francisco area. Where the heat suggest there being reported an incident. The time series goes through every month since 2003 up until december 2024. The heatmap suggest that the incidents mainly happens in the eastwestern/eastern part of san francisco. The heat maps also suggests that there has been an decrease in number of incidents over the years.\n\n\n\n\nFrom the heatmap its clear that a lot of the incidents happen in the north-eastern/eastern part of san francisco. Even after the massive drop of vehicle thefts it still seems to be primarily a given area. This might suggest that there are some factors that make the area more prone to car thefts. The time series heatmap shows the density of crimes dropping when looking at 2003-2005 versus 2006-2025. This is as expected. You can also see the increase from 2010 and 2020 as previously discussed."
  },
  {
    "objectID": "index.html#conclusion",
    "href": "index.html#conclusion",
    "title": "Looking at Vehicle thefts from 2003-2024 in",
    "section": "Conclusion",
    "text": "Conclusion\nWe have in this article looked at three different plots. Where in particularly the temporal and corelation plots suggest that the trend of vehicle thefts incidents are unique compared to the temporal trends of other crimes. This is concluded both because the number of vehicle thefts drop by approximately 60% in one year. But also because the corelation between number of vehicle thefts compared to the incident number of other crimes are generally close to zero. A news article from 2007 explains that the san francisco police department set up 16 auto-theft task forces and generally caught a lot of car thieves in 2006. This might explain why there was a sudden drop in vehicle theft incidents. This also might explain why the different crimes are not as much correlated with vehicle theft as they are with each other."
  }
]