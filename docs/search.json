[
  {
    "objectID": "Workingfile_website_2.html",
    "href": "Workingfile_website_2.html",
    "title": "Assignment 2 - Social Data Analysis and Visualization",
    "section": "",
    "text": "import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\ndata=pd.read_csv(\"C:/NoterDTU/6_semester/Social_data/website_2/merged_data.csv\")\n\n\nimport pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\ndata=pd.read_csv(\"C:/NoterDTU/6_semester/Social_data/website_2/merged_data.csv\")\ncrimes = data[['Category', 'Year']]\ncrimes = crimes[(crimes['Category']=='VEHICLE THEFT') & (crimes['Year']!=2025)  ]\ncrime_counts = crimes[\"Year\"].value_counts().sort_index()\ncrime_counts.plot(kind=\"bar\",color=\"indigo\",edgecolor=\"black\")\nplt.show()\n\n\n\n\n\n\n\n\n\nfocuscrimes = set(['WEAPON LAWS', 'PROSTITUTION', 'ROBBERY', 'BURGLARY', 'ASSAULT', 'DRUG/NARCOTIC', 'LARCENY/THEFT', 'VANDALISM', 'VEHICLE THEFT', 'STOLEN PROPERTY'])\n\n\ndata[\"Year\"].value_counts().sort_index().plot(kind=\"bar\",color=\"indigo\",edgecolor=\"black\")\nplt.ylabel(\"Number of crimes\")\nplt.xlabel(\"Year\")\nplt.title(\"Number of crimes per year (2003-2025)\")\n\nText(0.5, 1.0, 'Number of crimes per year (2003-2025)')\n\n\n\n\n\n\n\n\n\n\ncrimes = data[['Category', 'Year']]\ncrimes = crimes[(crimes['Category']=='VEHICLE THEFT') & (crimes['Year']!=2025)  ]\ncrime_counts = crimes[\"Year\"].value_counts().sort_index()\ncrime_counts.plot(kind=\"bar\",color=\"indigo\",edgecolor=\"black\")\nplt.show()\n\n\n\n\n\n\n\n\n\nimport pandas as pd\nimport folium\nfrom folium.plugins import HeatMapWithTime\nfrom IPython.display import display\n\n# Load data\ndf = pd.read_csv(\"C:/NoterDTU/6_semester/Social_data/website_2/merged_data.csv\")\n\n# Filter for vehicle thefts between 2003-2007\ndf_filtered = df[(df['Category'] == 'VEHICLE THEFT') & \n                 (df['Year'].between(2003, 2024))].copy()\n\n# Check if filtered data is empty\nif df_filtered.empty:\n    print(\"Warning: No data after filtering!\")\nelse:\n    print(f\"Found {len(df_filtered)} records after filtering\")\n\n# Extract relevant columns and drop NA\ndf_filtered = df_filtered[['Latitude', 'Longitude', 'Month', 'Year']].dropna()\n\n# Check for valid coordinates\nvalid_coords = df_filtered[\n    (df_filtered['Latitude'].between(-90, 90)) & \n    (df_filtered['Longitude'].between(-180, 180))\n]\nif len(valid_coords) &lt; len(df_filtered):\n    print(f\"Warning: {len(df_filtered) - len(valid_coords)} records have invalid coordinates\")\n\n# Define month mapping and order\nmonth_mapping = {\n    \"January\": 1, \"February\": 2, \"March\": 3, \"April\": 4, \n    \"May\": 5, \"June\": 6, \"July\": 7, \"August\": 8, \n    \"September\": 9, \"October\": 10, \"November\": 11, \"December\": 12\n}\nmonth_names = list(month_mapping.keys())\n\n# Create numerical month column\ndf_filtered['MonthNum'] = df_filtered['Month'].map(month_mapping)\n\n# Sort by year and month\ndf_filtered = df_filtered.sort_values(['Year', 'MonthNum'])\n\n# Prepare heat data and time index\nheat_data = []\ntime_index = []\n\nfor year in range(2003, 2025):\n    for month_num in range(1, 13):\n        month_data = df_filtered[\n            (df_filtered['Year'] == year) & \n            (df_filtered['MonthNum'] == month_num)\n        ]\n        coords = month_data[['Latitude', 'Longitude']].values.tolist()\n        heat_data.append(coords)\n        time_index.append(f\"{month_names[month_num-1]} {year}\")\n        \n        # Print count for debugging\n        print(f\"{month_names[month_num-1]} {year}: {len(coords)} points\")\n\n# Only create map if we have data\nif any(len(data) &gt; 0 for data in heat_data):\n    # Create base map\n    base_map = folium.Map(location=[37.77919, -122.41914], zoom_start=12.5)\n    \n    # Add heatmap with time\n    HeatMapWithTime(\n        heat_data,\n        index=time_index,  # Time labels showing month and year\n        auto_play=True,\n        max_opacity=0.5,\n        radius=13,\n        min_opacity=0.1,\n        gradient={0.2: 'blue', 0.4: 'lime', 0.6: 'orange', 0.8: 'red'},\n        display_index=True,\n        use_local_extrema=False, \n        name=\"Vehicle Thefts\",\n        blur=1\n    ).add_to(base_map)\n    \n    # Add layer control\n    folium.LayerControl().add_to(base_map)\n    \n    # Display map\n    display(base_map)\n\nFound 175849 records after filtering\nJanuary 2003: 1130 points\nFebruary 2003: 1085 points\nMarch 2003: 1406 points\nApril 2003: 1440 points\nMay 2003: 1296 points\nJune 2003: 1219 points\nJuly 2003: 1257 points\nAugust 2003: 1401 points\nSeptember 2003: 1373 points\nOctober 2003: 1302 points\nNovember 2003: 1175 points\nDecember 2003: 1192 points\nJanuary 2004: 1364 points\nFebruary 2004: 1315 points\nMarch 2004: 1482 points\nApril 2004: 1507 points\nMay 2004: 1602 points\nJune 2004: 1439 points\nJuly 2004: 1468 points\nAugust 2004: 1532 points\nSeptember 2004: 1404 points\nOctober 2004: 1532 points\nNovember 2004: 1550 points\nDecember 2004: 1621 points\nJanuary 2005: 1681 points\nFebruary 2005: 1362 points\nMarch 2005: 1473 points\nApril 2005: 1586 points\nMay 2005: 1580 points\nJune 2005: 1385 points\nJuly 2005: 1414 points\nAugust 2005: 1404 points\nSeptember 2005: 1420 points\nOctober 2005: 1766 points\nNovember 2005: 1714 points\nDecember 2005: 1318 points\nJanuary 2006: 604 points\nFebruary 2006: 567 points\nMarch 2006: 562 points\nApril 2006: 571 points\nMay 2006: 540 points\nJune 2006: 650 points\nJuly 2006: 671 points\nAugust 2006: 685 points\nSeptember 2006: 570 points\nOctober 2006: 628 points\nNovember 2006: 603 points\nDecember 2006: 612 points\nJanuary 2007: 521 points\nFebruary 2007: 465 points\nMarch 2007: 511 points\nApril 2007: 407 points\nMay 2007: 374 points\nJune 2007: 486 points\nJuly 2007: 633 points\nAugust 2007: 707 points\nSeptember 2007: 690 points\nOctober 2007: 616 points\nNovember 2007: 541 points\nDecember 2007: 493 points\nJanuary 2008: 518 points\nFebruary 2008: 475 points\nMarch 2008: 525 points\nApril 2008: 536 points\nMay 2008: 510 points\nJune 2008: 426 points\nJuly 2008: 460 points\nAugust 2008: 509 points\nSeptember 2008: 579 points\nOctober 2008: 575 points\nNovember 2008: 443 points\nDecember 2008: 486 points\nJanuary 2009: 545 points\nFebruary 2009: 400 points\nMarch 2009: 458 points\nApril 2009: 395 points\nMay 2009: 401 points\nJune 2009: 393 points\nJuly 2009: 435 points\nAugust 2009: 488 points\nSeptember 2009: 433 points\nOctober 2009: 414 points\nNovember 2009: 434 points\nDecember 2009: 374 points\nJanuary 2010: 366 points\nFebruary 2010: 363 points\nMarch 2010: 351 points\nApril 2010: 325 points\nMay 2010: 271 points\nJune 2010: 366 points\nJuly 2010: 386 points\nAugust 2010: 380 points\nSeptember 2010: 403 points\nOctober 2010: 357 points\nNovember 2010: 396 points\nDecember 2010: 372 points\nJanuary 2011: 334 points\nFebruary 2011: 311 points\nMarch 2011: 460 points\nApril 2011: 359 points\nMay 2011: 374 points\nJune 2011: 348 points\nJuly 2011: 274 points\nAugust 2011: 370 points\nSeptember 2011: 453 points\nOctober 2011: 510 points\nNovember 2011: 451 points\nDecember 2011: 499 points\nJanuary 2012: 428 points\nFebruary 2012: 473 points\nMarch 2012: 451 points\nApril 2012: 470 points\nMay 2012: 455 points\nJune 2012: 496 points\nJuly 2012: 600 points\nAugust 2012: 573 points\nSeptember 2012: 547 points\nOctober 2012: 551 points\nNovember 2012: 578 points\nDecember 2012: 552 points\nJanuary 2013: 522 points\nFebruary 2013: 470 points\nMarch 2013: 454 points\nApril 2013: 440 points\nMay 2013: 503 points\nJune 2013: 513 points\nJuly 2013: 495 points\nAugust 2013: 583 points\nSeptember 2013: 698 points\nOctober 2013: 567 points\nNovember 2013: 453 points\nDecember 2013: 536 points\nJanuary 2014: 517 points\nFebruary 2014: 442 points\nMarch 2014: 527 points\nApril 2014: 649 points\nMay 2014: 641 points\nJune 2014: 682 points\nJuly 2014: 650 points\nAugust 2014: 645 points\nSeptember 2014: 495 points\nOctober 2014: 703 points\nNovember 2014: 566 points\nDecember 2014: 584 points\nJanuary 2015: 606 points\nFebruary 2015: 550 points\nMarch 2015: 626 points\nApril 2015: 728 points\nMay 2015: 825 points\nJune 2015: 716 points\nJuly 2015: 633 points\nAugust 2015: 628 points\nSeptember 2015: 627 points\nOctober 2015: 709 points\nNovember 2015: 638 points\nDecember 2015: 649 points\nJanuary 2016: 565 points\nFebruary 2016: 543 points\nMarch 2016: 508 points\nApril 2016: 511 points\nMay 2016: 493 points\nJune 2016: 477 points\nJuly 2016: 531 points\nAugust 2016: 562 points\nSeptember 2016: 482 points\nOctober 2016: 602 points\nNovember 2016: 586 points\nDecember 2016: 557 points\nJanuary 2017: 484 points\nFebruary 2017: 507 points\nMarch 2017: 571 points\nApril 2017: 547 points\nMay 2017: 462 points\nJune 2017: 461 points\nJuly 2017: 496 points\nAugust 2017: 456 points\nSeptember 2017: 434 points\nOctober 2017: 580 points\nNovember 2017: 318 points\nDecember 2017: 389 points\nJanuary 2018: 773 points\nFebruary 2018: 677 points\nMarch 2018: 749 points\nApril 2018: 740 points\nMay 2018: 524 points\nJune 2018: 471 points\nJuly 2018: 476 points\nAugust 2018: 430 points\nSeptember 2018: 438 points\nOctober 2018: 484 points\nNovember 2018: 443 points\nDecember 2018: 455 points\nJanuary 2019: 411 points\nFebruary 2019: 397 points\nMarch 2019: 405 points\nApril 2019: 436 points\nMay 2019: 437 points\nJune 2019: 448 points\nJuly 2019: 448 points\nAugust 2019: 419 points\nSeptember 2019: 471 points\nOctober 2019: 454 points\nNovember 2019: 481 points\nDecember 2019: 464 points\nJanuary 2020: 477 points\nFebruary 2020: 473 points\nMarch 2020: 511 points\nApril 2020: 521 points\nMay 2020: 602 points\nJune 2020: 669 points\nJuly 2020: 812 points\nAugust 2020: 651 points\nSeptember 2020: 526 points\nOctober 2020: 664 points\nNovember 2020: 744 points\nDecember 2020: 763 points\nJanuary 2021: 752 points\nFebruary 2021: 623 points\nMarch 2021: 591 points\nApril 2021: 567 points\nMay 2021: 666 points\nJune 2021: 600 points\nJuly 2021: 658 points\nAugust 2021: 661 points\nSeptember 2021: 607 points\nOctober 2021: 767 points\nNovember 2021: 645 points\nDecember 2021: 701 points\nJanuary 2022: 694 points\nFebruary 2022: 723 points\nMarch 2022: 643 points\nApril 2022: 590 points\nMay 2022: 582 points\nJune 2022: 636 points\nJuly 2022: 675 points\nAugust 2022: 692 points\nSeptember 2022: 730 points\nOctober 2022: 738 points\nNovember 2022: 700 points\nDecember 2022: 677 points\nJanuary 2023: 656 points\nFebruary 2023: 646 points\nMarch 2023: 730 points\nApril 2023: 737 points\nMay 2023: 831 points\nJune 2023: 755 points\nJuly 2023: 916 points\nAugust 2023: 770 points\nSeptember 2023: 770 points\nOctober 2023: 713 points\nNovember 2023: 667 points\nDecember 2023: 610 points\nJanuary 2024: 698 points\nFebruary 2024: 675 points\nMarch 2024: 592 points\nApril 2024: 519 points\nMay 2024: 565 points\nJune 2024: 616 points\nJuly 2024: 738 points\nAugust 2024: 622 points\nSeptember 2024: 586 points\nOctober 2024: 524 points\nNovember 2024: 427 points\nDecember 2024: 465 points\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\nfrom bokeh.io import output_notebook, show\nfrom bokeh.layouts import column\nfrom bokeh.models import Select, Slope, Label, CustomJS, HoverTool\nfrom bokeh.plotting import figure, ColumnDataSource\nimport numpy as np\nimport pandas as pd\n\n# Configure Bokeh to load silently\noutput_notebook(hide_banner=True)\n\n# Load and prepare your crime data\ndf = pd.read_csv(\"C:/NoterDTU/6_semester/Social_data/website_2/merged_data.csv\")\n\n# Define focus crimes\nfocuscrimes = {\n    'WEAPON LAWS', 'PROSTITUTION', 'ROBBERY', 'BURGLARY', 'ASSAULT', \n    'DRUG/NARCOTIC', 'LARCENY/THEFT', 'VANDALISM', 'VEHICLE THEFT', 'STOLEN PROPERTY'\n}\n\n# Filter and process data\ndf_focus = df[df['Category'].isin(focuscrimes)]\ndf_focus_grouped = df_focus.groupby(['Year', 'Month', 'Category']).size().reset_index(name='Crime_Count')\ndf_focus_grouped['Date'] = pd.to_datetime(df_focus_grouped['Month'] + ' ' + df_focus_grouped['Year'].astype(str), errors='coerce')\ndf_focus_grouped = df_focus_grouped.dropna()\n\n# Extract month and year for hover tool\ndf_focus_grouped['Month_Year'] = df_focus_grouped['Date'].dt.strftime('%b %Y')\n\n# Pivot the data\ndf_pivot = df_focus_grouped.pivot_table(index=['Date', 'Month_Year'], columns='Category', values='Crime_Count', fill_value=0)\ndf_pivot['Total Crimes'] = df_pivot.sum(axis=1)\ndf_pivot.reset_index(inplace=True)\n\n# Prepare plotting data\nnumeric_cols = [col for col in df_pivot.columns if col not in ['Date', 'Month_Year']]\ndf_plot = df_pivot[numeric_cols]\n\n# Set initial variables\nx_init = numeric_cols[8]\ny_init = numeric_cols[1]\nx_data = df_plot[x_init].values\ny_data = df_plot[y_init].values\n\n# Calculate initial regression\nn = len(x_data)\nx_sum, y_sum, xy_sum, x2_sum, y2_sum = x_data.sum(), y_data.sum(), (x_data*y_data).sum(), (x_data**2).sum(), (y_data**2).sum()\nslope_val = (n * xy_sum - x_sum * y_sum) / (n * x2_sum - x_sum * x_sum)\nintercept = (y_sum - slope_val * x_sum) / n\nr_value = (n * xy_sum - x_sum * y_sum) / np.sqrt((n * x2_sum - x_sum * x_sum) * (n * y2_sum - y_sum * y_sum))\nr_squared = r_value ** 2\n\n# Create ColumnDataSource with Month_Year for hover tool\nsource = ColumnDataSource(df_pivot)\n\n# Create figure with initial axis labels\nplot = figure(\n    title=\"Crime Data Correlation Analysis\", \n    x_axis_label=\"Number of incidents for X-axis crime type (month,year)\",\n    y_axis_label=\"Number of incidents for Y-axis crime type (month,year)\",\n    tools=\"pan,wheel_zoom,box_zoom,reset\",\n    width=750, \n    height=550,\n    background_fill_color=\"#f5f5f5\",\n    toolbar_location=\"above\"\n)\n\n# Format plot appearance\nplot.title.text_font_size = '16pt'\nplot.xaxis.axis_label_text_font_size = \"12pt\"\nplot.yaxis.axis_label_text_font_size = \"12pt\"\nplot.grid.grid_line_alpha = 0.3\n\n# Add only the month-year hover tool\nhover = HoverTool(\n    tooltips=[\n        (\"Time Period\", \"@Month_Year\"),\n        (x_init, f\"@{{{x_init}}}\"),\n        (y_init, f\"@{{{y_init}}}\"),\n        (\"Total Crimes\", \"@{Total Crimes}\")\n    ],\n    mode='mouse'\n)\nplot.add_tools(hover)\n\n# Initial scatter plot\nscatter = plot.scatter(x=x_init, y=y_init, source=source, size=10,\n                      color=\"navy\", alpha=0.7, line_color=\"white\")\n\n# Dropdown widgets\nx_axis = Select(title=\"X-Axis Crime Type:\", value=x_init,\n               options=sorted(numeric_cols), width=250)\ny_axis = Select(title=\"Y-Axis Crime Type:\", value=y_init,\n               options=sorted(numeric_cols), width=250)\n\n# Regression line\nslope = Slope(gradient=slope_val, y_intercept=intercept, \n             line_color='red', line_dash='dashed', line_width=2.5)\nplot.add_layout(slope)\n\n# R¬≤ label\nr_squared_label = Label(x=70, y=10, x_units='screen', y_units='screen',\n                       text=f\"R¬≤ = {r_squared:.3f}\", text_font_size='13px',\n                       text_color='red', background_fill_color='white',\n                       background_fill_alpha=0.8)\nplot.add_layout(r_squared_label)\n\n# JavaScript callback with axis label updates\ncallback = CustomJS(args=dict(\n    source=source,\n    scatter=scatter,\n    slope=slope,\n    r_squared_label=r_squared_label,\n    plot=plot,\n    x_axis=x_axis,\n    y_axis=y_axis\n), code=\"\"\"\n    const x = x_axis.value;\n    const y = y_axis.value;\n    const x_data = source.data[x];\n    const y_data = source.data[y];\n    \n    // Calculate statistics\n    let x_sum = 0, y_sum = 0, xy_sum = 0, x2_sum = 0, y2_sum = 0;\n    const n = x_data.length;\n    \n    for (let i = 0; i &lt; n; i++) {\n        x_sum += x_data[i];\n        y_sum += y_data[i];\n        xy_sum += x_data[i] * y_data[i];\n        x2_sum += x_data[i] * x_data[i];\n        y2_sum += y_data[i] * y_data[i];\n    }\n    \n    // Calculate regression parameters\n    const slope_val = (n * xy_sum - x_sum * y_sum) / (n * x2_sum - x_sum * x_sum);\n    const intercept = (y_sum - slope_val * x_sum) / n;\n    const r_value = (n * xy_sum - x_sum * y_sum) / \n                   Math.sqrt((n * x2_sum - x_sum * x_sum) * (n * y2_sum - y_sum * y_sum));\n    const r_squared = r_value * r_value;\n    \n    // Update plot elements\n    scatter.glyph.x = {field: x};\n    scatter.glyph.y = {field: y};\n    slope.gradient = slope_val;\n    slope.y_intercept = intercept;\n    r_squared_label.text = `R¬≤ = ${r_squared.toFixed(3)}`;\n    \n    // Update axis labels\n    plot.xaxis.axis_label = `${x} (Count)`;\n    plot.yaxis.axis_label = `${y} (Count)`;\n\"\"\")\n\n# Connect callbacks\nx_axis.js_on_change('value', callback)\ny_axis.js_on_change('value', callback)\n\n# Layout\nlayout = column(\n    column(x_axis, y_axis, width=300),\n    plot\n)\n\n# Show the plot\nshow(layout)\n#yes"
  },
  {
    "objectID": "hw2.html",
    "href": "hw2.html",
    "title": "Assignment unga bunga",
    "section": "",
    "text": "Code\nimport pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\ndata=pd.read_csv(\"C:/NoterDTU/6_semester/Social_data/website_2/s224394.github.io/merged_data.csv\")\ncrimes = data[['Category', 'Year']]\ncrimes = crimes[(crimes['Category']=='VEHICLE THEFT') & (crimes['Year']!=2025)  ]\ncrime_counts = crimes[\"Year\"].value_counts().sort_index()\ncrime_counts.plot(kind=\"bar\",color=\"indigo\",edgecolor=\"black\")\nplt.ylabel(\"Number of incidents\")\nplt.xlabel(\"Year\")\nplt.title(\"Number of Vehicle thefts per year (2003-2025)\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nimport pandas as pd\nimport folium\nfrom folium.plugins import HeatMapWithTime\nfrom IPython.display import display\n\n# Load data\ndf = pd.read_csv(\"C:/NoterDTU/6_semester/Social_data/website_2/s224394.github.io/merged_data.csv\")\n\n# Filter for vehicle thefts between 2003-2007\ndf_filtered = df[(df['Category'] == 'VEHICLE THEFT') & \n                 (df['Year'].between(2003, 2024))].copy()\n\n# Extract relevant columns and drop NA\ndf_filtered = df_filtered[['Latitude', 'Longitude', 'Month', 'Year']].dropna()\n\n# Check for valid coordinates\nvalid_coords = df_filtered[\n    (df_filtered['Latitude'].between(-90, 90)) & \n    (df_filtered['Longitude'].between(-180, 180))\n]\n\n# Define month mapping and order\nmonth_mapping = {\n    \"January\": 1, \"February\": 2, \"March\": 3, \"April\": 4, \n    \"May\": 5, \"June\": 6, \"July\": 7, \"August\": 8, \n    \"September\": 9, \"October\": 10, \"November\": 11, \"December\": 12\n}\nmonth_names = list(month_mapping.keys())\n\n# Create numerical month column\ndf_filtered['MonthNum'] = df_filtered['Month'].map(month_mapping)\n\n# Sort by year and month\ndf_filtered = df_filtered.sort_values(['Year', 'MonthNum'])\n\n# Prepare heat data and time index\nheat_data = []\ntime_index = []\n\nfor year in range(2003, 2025):\n    for month_num in range(1, 13):\n        month_data = df_filtered[\n            (df_filtered['Year'] == year) & \n            (df_filtered['MonthNum'] == month_num)\n        ]\n        coords = month_data[['Latitude', 'Longitude']].values.tolist()\n        heat_data.append(coords)\n        time_index.append(f\"{month_names[month_num-1]} {year}\")\n        \n\n# Only create map if we have data\n\n# Create base map\nbase_map = folium.Map(location=[37.77919, -122.41914], zoom_start=12.5)\n\n# Add heatmap with time\nHeatMapWithTime(\n    heat_data,\n    index=time_index,  # Time labels showing month and year\n    auto_play=0,\n    max_opacity=0.5,\n    radius=13,\n    min_opacity=0.1,\n    gradient={0.2: 'blue', 0.4: 'lime', 0.6: 'orange', 0.8: 'red'},\n    display_index=True,\n    use_local_extrema=False, \n    name=\"Vehicle Thefts\",\n    blur=1\n).add_to(base_map)\n\n# Display map\ndisplay(base_map)\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\n\nCode\nfrom bokeh.io import output_notebook, show\nfrom bokeh.layouts import column\nfrom bokeh.models import Select, Slope, Label, CustomJS, HoverTool\nfrom bokeh.plotting import figure, ColumnDataSource\nimport numpy as np\nimport pandas as pd\n\n# Configure Bokeh to load silently\noutput_notebook(hide_banner=True)\n\n# Load and prepare your crime data\ndf =pd.read_csv(\"C:/NoterDTU/6_semester/Social_data/website_2/s224394.github.io/merged_data.csv\")\n\n# Define focus crimes\nfocuscrimes = {\n    'WEAPON LAWS', 'PROSTITUTION', 'ROBBERY', 'BURGLARY', 'ASSAULT', \n    'DRUG/NARCOTIC', 'LARCENY/THEFT', 'VANDALISM', 'VEHICLE THEFT', 'STOLEN PROPERTY'\n}\n\n# Filter and process data\ndf_focus = df[df['Category'].isin(focuscrimes)]\ndf_focus_grouped = df_focus.groupby(['Year', 'Month', 'Category']).size().reset_index(name='Crime_Count')\ndf_focus_grouped['Date'] = pd.to_datetime(df_focus_grouped['Month'] + ' ' + df_focus_grouped['Year'].astype(str), errors='coerce')\ndf_focus_grouped = df_focus_grouped.dropna()\n\n# Extract month and year for hover tool\ndf_focus_grouped['Month_Year'] = df_focus_grouped['Date'].dt.strftime('%b %Y')\n\n# Pivot the data\ndf_pivot = df_focus_grouped.pivot_table(index=['Date', 'Month_Year'], columns='Category', values='Crime_Count', fill_value=0)\ndf_pivot['Total Crimes'] = df_pivot.sum(axis=1)\ndf_pivot.reset_index(inplace=True)\n\n# Prepare plotting data\nnumeric_cols = [col for col in df_pivot.columns if col not in ['Date', 'Month_Year']]\ndf_plot = df_pivot[numeric_cols]\n\n# Set initial variables\nx_init = numeric_cols[8]\ny_init = numeric_cols[1]\nx_data = df_plot[x_init].values\ny_data = df_plot[y_init].values\n\n# Calculate initial regression\nn = len(x_data)\nx_sum, y_sum, xy_sum, x2_sum, y2_sum = x_data.sum(), y_data.sum(), (x_data*y_data).sum(), (x_data**2).sum(), (y_data**2).sum()\nslope_val = (n * xy_sum - x_sum * y_sum) / (n * x2_sum - x_sum * x_sum)\nintercept = (y_sum - slope_val * x_sum) / n\nr_value = (n * xy_sum - x_sum * y_sum) / np.sqrt((n * x2_sum - x_sum * x_sum) * (n * y2_sum - y_sum * y_sum))\nr_squared = r_value ** 2\n\n# Create ColumnDataSource with Month_Year for hover tool\nsource = ColumnDataSource(df_pivot)\n\n# Create figure with initial axis labels\nplot = figure(\n    title=\"Crime Data Correlation Analysis\", \n    x_axis_label=\"Number of incidents for X-axis crime type (month,year)\",\n    y_axis_label=\"Number of incidents for Y-axis crime type (month,year)\",\n    tools=\"pan,wheel_zoom,box_zoom,reset\",\n    width=750, \n    height=550,\n    background_fill_color=\"#f5f5f5\",\n    toolbar_location=\"above\"\n)\n\n# Format plot appearance\nplot.title.text_font_size = '16pt'\nplot.xaxis.axis_label_text_font_size = \"12pt\"\nplot.yaxis.axis_label_text_font_size = \"12pt\"\nplot.grid.grid_line_alpha = 0.3\n\n# Add only the month-year hover tool\nhover = HoverTool(\n    tooltips=[\n        (\"Time Period\", \"@Month_Year\"),\n        (x_init, f\"@{{{x_init}}}\"),\n        (y_init, f\"@{{{y_init}}}\"),\n        (\"Total Crimes\", \"@{Total Crimes}\")\n    ],\n    mode='mouse'\n)\nplot.add_tools(hover)\n\n# Initial scatter plot\nscatter = plot.scatter(x=x_init, y=y_init, source=source, size=10,\n                      color=\"navy\", alpha=0.7, line_color=\"white\")\n\n# Dropdown widgets\nx_axis = Select(title=\"X-Axis Crime Type:\", value=x_init,\n               options=sorted(numeric_cols), width=250)\ny_axis = Select(title=\"Y-Axis Crime Type:\", value=y_init,\n               options=sorted(numeric_cols), width=250)\n\n# Regression line\nslope = Slope(gradient=slope_val, y_intercept=intercept, \n             line_color='red', line_dash='dashed', line_width=2.5)\nplot.add_layout(slope)\n\n# R¬≤ label\nr_squared_label = Label(x=70, y=10, x_units='screen', y_units='screen',\n                       text=f\"R¬≤ = {r_squared:.3f}\", text_font_size='13px',\n                       text_color='red', background_fill_color='white',\n                       background_fill_alpha=0.8)\nplot.add_layout(r_squared_label)\n\n# JavaScript callback with axis label updates\ncallback = CustomJS(args=dict(\n    source=source,\n    scatter=scatter,\n    slope=slope,\n    r_squared_label=r_squared_label,\n    plot=plot,\n    x_axis=x_axis,\n    y_axis=y_axis\n), code=\"\"\"\n    const x = x_axis.value;\n    const y = y_axis.value;\n    const x_data = source.data[x];\n    const y_data = source.data[y];\n    \n    // Calculate statistics\n    let x_sum = 0, y_sum = 0, xy_sum = 0, x2_sum = 0, y2_sum = 0;\n    const n = x_data.length;\n    \n    for (let i = 0; i &lt; n; i++) {\n        x_sum += x_data[i];\n        y_sum += y_data[i];\n        xy_sum += x_data[i] * y_data[i];\n        x2_sum += x_data[i] * x_data[i];\n        y2_sum += y_data[i] * y_data[i];\n    }\n    \n    // Calculate regression parameters\n    const slope_val = (n * xy_sum - x_sum * y_sum) / (n * x2_sum - x_sum * x_sum);\n    const intercept = (y_sum - slope_val * x_sum) / n;\n    const r_value = (n * xy_sum - x_sum * y_sum) / \n                   Math.sqrt((n * x2_sum - x_sum * x_sum) * (n * y2_sum - y_sum * y_sum));\n    const r_squared = r_value * r_value;\n    \n    // Update plot elements\n    scatter.glyph.x = {field: x};\n    scatter.glyph.y = {field: y};\n    slope.gradient = slope_val;\n    slope.y_intercept = intercept;\n    r_squared_label.text = `R¬≤ = ${r_squared.toFixed(3)}`;\n    \n    // Update axis labels\n    plot.xaxis.axis_label = `${x} (Count)`;\n    plot.yaxis.axis_label = `${y} (Count)`;\n\"\"\")\n\n# Connect callbacks\nx_axis.js_on_change('value', callback)\ny_axis.js_on_change('value', callback)\n\n# Layout\nlayout = column(\n    column(x_axis, y_axis, width=300),\n    plot\n)\n\n# Show the plot\nshow(layout)\n\n\n\n  \n\n\n\n\n\nCode\n2+2\n\n\n4"
  },
  {
    "objectID": "hello.html",
    "href": "hello.html",
    "title": "Quarto Basics",
    "section": "",
    "text": "For a demonstration of a line plot on a polar axis, see Figure¬†1.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 1, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nFigure¬†1: A line plot on a polar axis\n\n\n\n\n\nHello? is this thing working???"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Looking at Vehicle thefts from 2003-2024 in",
    "section": "",
    "text": "Since the year 2003 the police department of san francisco has been reporting crime data. Of particular intererest for analysis is the different crime types, the time of incident (both date but also time of day down to the minute) but also the coordinates of the incident (given in latitude/longitude). From this data its possible to look at temporal and spatial trends of different crimes over the last 20+ years. The different categoris of crimes include Vehicle theft, vandalism, robbery, prostiution and many more. I have choosen to look at the trends of vehicle thefts since the trend in many ways are unique compared to the other types of crimes, but i will go more into detail later."
  },
  {
    "objectID": "index.html#the-data",
    "href": "index.html#the-data",
    "title": "Looking at Vehicle thefts from 2003-2024 in",
    "section": "",
    "text": "Since the year 2003 the police department of san francisco has been reporting crime data. Of particular intererest for analysis is the different crime types, the time of incident (both date but also time of day down to the minute) but also the coordinates of the incident (given in latitude/longitude). From this data its possible to look at temporal and spatial trends of different crimes over the last 20+ years. The different categoris of crimes include Vehicle theft, vandalism, robbery, prostiution and many more. I have choosen to look at the trends of vehicle thefts since the trend in many ways are unique compared to the other types of crimes, but i will go more into detail later."
  },
  {
    "objectID": "index.html#the-temporal-trend-of-vehicle-thefts",
    "href": "index.html#the-temporal-trend-of-vehicle-thefts",
    "title": "Looking at Vehicle thefts from 2003-2024 in",
    "section": "The temporal trend of vehicle thefts",
    "text": "The temporal trend of vehicle thefts\nThe first super relevant thing is to look at how the number of incidents of vehicle theft have evolved over time.\n\n\nCode\nimport pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\ndata=pd.read_csv(\"C:/NoterDTU/6_semester/Social_data/website_2/s224394.github.io/merged_data.csv\")\ncrimes = data[['Category', 'Year']]\ncrimes = crimes[(crimes['Category']=='VEHICLE THEFT') & (crimes['Year']!=2025)  ]\ncrime_counts = crimes[\"Year\"].value_counts().sort_index()\ncrime_counts.plot(kind=\"bar\",color=\"indigo\",edgecolor=\"black\")\nplt.ylabel(\"Number of incidents\")\nplt.xlabel(\"Year\")\nplt.title(\"Number of Vehicle thefts per year (2003-2024)\")\nplt.show()\n\n\n\n\n\n\n\n\n\nOne thing one notices almost immedialty is the sudden drop from 2005 to 2006 and onwards. In 2005 the numbers peak at around 17.500 vehicle thefts while the next years it drops by around 10.000 and remains in that range going forward. This approximately 60% of the crimes that just stopped happening in one year. That seems quite strange. Some sources suggest that the fact that cars are hard to break into and harder to dissamble might be üòÄ\nWe will later compare vehicle theft to some other crimes in order to see if this was the overall trend of crime data (spoilers its not)"
  },
  {
    "objectID": "index.html#the-spatial-trends",
    "href": "index.html#the-spatial-trends",
    "title": "Looking at Vehicle thefts from 2003-2024 in",
    "section": "The spatial trends",
    "text": "The spatial trends\nOne thing one might suspect could explain the sudden drop is if there suddenly where a focus from the police deparment on a specific area. As previously mentioned they have the data for where the different crimes are happening and one would then think that they then priotize forces in these specific areas. In order to look at the we plot a time series of where the incidents of vehecle theft is happening for a given month and try to see if there is any difference.\n\n\nCode\nimport folium\nfrom folium.plugins import HeatMapWithTime\nfrom IPython.display import display\n\n# Load data\ndf = pd.read_csv(\"C:/NoterDTU/6_semester/Social_data/website_2/s224394.github.io/merged_data.csv\")\n\n# Filter for vehicle thefts between 2003-2007\ndf_filtered = df[(df['Category'] == 'VEHICLE THEFT') & \n                 (df['Year'].between(2003, 2024))].copy()\n\n# Extract relevant columns and drop NA\ndf_filtered = df_filtered[['Latitude', 'Longitude', 'Month', 'Year']].dropna()\n\n# Check for valid coordinates\nvalid_coords = df_filtered[\n    (df_filtered['Latitude'].between(-90, 90)) & \n    (df_filtered['Longitude'].between(-180, 180))\n]\n\n# Define month mapping and order\nmonth_mapping = {\n    \"January\": 1, \"February\": 2, \"March\": 3, \"April\": 4, \n    \"May\": 5, \"June\": 6, \"July\": 7, \"August\": 8, \n    \"September\": 9, \"October\": 10, \"November\": 11, \"December\": 12\n}\nmonth_names = list(month_mapping.keys())\n\n# Create numerical month column\ndf_filtered['MonthNum'] = df_filtered['Month'].map(month_mapping)\n\n# Sort by year and month\ndf_filtered = df_filtered.sort_values(['Year', 'MonthNum'])\n\n# Prepare heat data and time index\nheat_data = []\ntime_index = []\n\nfor year in range(2003, 2025):\n    for month_num in range(1, 13):\n        month_data = df_filtered[\n            (df_filtered['Year'] == year) & \n            (df_filtered['MonthNum'] == month_num)\n        ]\n        coords = month_data[['Latitude', 'Longitude']].values.tolist()\n        heat_data.append(coords)\n        time_index.append(f\"{month_names[month_num-1]} {year}\")\n        \n\n# Only create map if we have data\n\n# Create base map\nbase_map = folium.Map(location=[37.75800, -122.41914], zoom_start=11.5,zoom_control=0,scrollWheelZoom=False,dragging=0)\n\n# Add heatmap with time\nHeatMapWithTime(\n    heat_data,\n    index=time_index,  # Time labels showing month and year\n    auto_play=0,\n    max_opacity=0.5,\n    radius=11,\n    min_opacity=0.1,\n    gradient={0.2: 'blue', 0.4: 'lime', 0.6: 'orange', 0.8: 'red'},\n    display_index=True,\n    use_local_extrema=1, \n    name=\"Vehicle Thefts\",\n    blur=1\n).add_to(base_map)\n\n# Display map\ndisplay(base_map)\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\nFrom the heatmap its clear that a lot of the incidents happen in the north-eastern/eastern part of san francisco. And that trend does not change as teh years go by. But its clear that there is fewer crimes compared to 2003-2005 and the years after since the point of the heat map are more spread out. üòé Hello is this thing working?\nThe news article ‚ÄúCar Thefts Decrease Statewide‚Äù (Staff 2007) also tells this story Where the general trend for vehicle theft are on the decline. The reason behind this trend is both the fact that more and more vehicle have implemented alarms, key-coding systems. But also there has also been set up 16 auto-theft task forces. There have also been an increase in the use of so called ‚Äúbait-cars‚Äù which are used as bait to track down the drivers and since its normal that they steal more than one car the number of cars that are being stolen drops significantly. In 2006 they made 357 arrest with the use of bait-cars. Which might have severely impacted the amount of cars stolen.\nAfter 2006 the number of incidents are generally low compared to\nLast thing that could be interesting to look at is if the trends in data are unique to car theft or if the over all trend of crime is the ‚Äúsame‚Äù as with the car theft."
  },
  {
    "objectID": "index.html#correlation-between-crimes",
    "href": "index.html#correlation-between-crimes",
    "title": "Looking at Vehicle thefts from 2003-2024 in",
    "section": "Correlation between crimes",
    "text": "Correlation between crimes\nIn order to compare the crimes. We choose to look at how correlated the different crimes are. What we are comparing is the amount of crimes for a given month example burglary versus vehicle theft in the month of january 2015. We can the make an scatter plot and compute how related the data are. The scatter plot might also show other trends. But we will get to that. üòé\n\n\nCode\nfrom bokeh.io import output_notebook, show\nfrom bokeh.layouts import column\nfrom bokeh.models import Select, Slope, Label, CustomJS, HoverTool\nfrom bokeh.plotting import figure, ColumnDataSource\n\n# Configure Bokeh to load silently\noutput_notebook(hide_banner=True)\n\n# Define focus crimes\nfocuscrimes = {\n    'WEAPON LAWS', 'PROSTITUTION', 'ROBBERY', 'BURGLARY', 'ASSAULT', \n    'DRUG/NARCOTIC', 'LARCENY/THEFT', 'VANDALISM', 'VEHICLE THEFT', 'STOLEN PROPERTY'\n}\n\n\n# Load data\ndf = pd.read_csv(\"C:/NoterDTU/6_semester/Social_data/website_2/s224394.github.io/merged_data.csv\")\n\n# Filter and process data\ndf_focus = df[df['Category'].isin(focuscrimes)]\ndf_focus_grouped = df_focus.groupby(['Year', 'Month', 'Category']).size().reset_index(name='Crime_Count')\ndf_focus_grouped['Date'] = pd.to_datetime(df_focus_grouped['Month'] + ' ' + df_focus_grouped['Year'].astype(str), errors='coerce')\ndf_focus_grouped = df_focus_grouped.dropna()\n\n# Extract month and year for hover tool\ndf_focus_grouped['Month_Year'] = df_focus_grouped['Date'].dt.strftime('%b %Y')\n\n# Pivot the data\ndf_pivot = df_focus_grouped.pivot_table(index=['Date', 'Month_Year'], columns='Category', values='Crime_Count', fill_value=0)\ndf_pivot['Total Crimes'] = df_pivot.sum(axis=1)\ndf_pivot.reset_index(inplace=True)\n\n# Prepare plotting data\nnumeric_cols = [col for col in df_pivot.columns if col not in ['Date', 'Month_Year']]\ndf_plot = df_pivot[numeric_cols]\n\n# Set initial variables\nx_init = numeric_cols[8]\ny_init = numeric_cols[1]\nx_data = df_plot[x_init].values\ny_data = df_plot[y_init].values\n\n# Calculate initial regression\nn = len(x_data)\nx_sum, y_sum, xy_sum, x2_sum, y2_sum = x_data.sum(), y_data.sum(), (x_data*y_data).sum(), (x_data**2).sum(), (y_data**2).sum()\nslope_val = (n * xy_sum - x_sum * y_sum) / (n * x2_sum - x_sum * x_sum)\nintercept = (y_sum - slope_val * x_sum) / n\nr_value = (n * xy_sum - x_sum * y_sum) / np.sqrt((n * x2_sum - x_sum * x_sum) * (n * y2_sum - y_sum * y_sum))\nr_squared = r_value ** 2\n\n# Create ColumnDataSource with Month_Year for hover tool\nsource = ColumnDataSource(df_pivot)\n\n# Create figure with initial axis labels\nplot = figure(\n    title=\"Crime Data Correlation Analysis\", \n    x_axis_label=\"Number of incidents for X-axis crime type (month,year)\",\n    y_axis_label=\"Number of incidents for Y-axis crime type (month,year)\",\n    tools=\"pan,wheel_zoom,box_zoom,reset\",\n    width=750, \n    height=550,\n    background_fill_color=\"#f5f5f5\",\n    toolbar_location=\"above\"\n)\n\n# Format plot appearance\nplot.title.text_font_size = '16pt'\nplot.xaxis.axis_label_text_font_size = \"12pt\"\nplot.yaxis.axis_label_text_font_size = \"12pt\"\nplot.grid.grid_line_alpha = 0.3\n\n# Add only the month-year hover tool\nhover = HoverTool(\n    tooltips=[\n        (\"Time Period\", \"@Month_Year\"),\n        (x_init, f\"@{{{x_init}}}\"),\n        (y_init, f\"@{{{y_init}}}\"),\n        (\"Total Crimes\", \"@{Total Crimes}\")\n    ],\n    mode='mouse'\n)\nplot.add_tools(hover)\n\n# Initial scatter plot\nscatter = plot.scatter(x=x_init, y=y_init, source=source, size=10,\n                      color=\"navy\", alpha=0.7, line_color=\"white\")\n\n# Dropdown widgets\nx_axis = Select(title=\"X-Axis Crime Type:\", value=x_init,\n               options=sorted(numeric_cols), width=250)\ny_axis = Select(title=\"Y-Axis Crime Type:\", value=y_init,\n               options=sorted(numeric_cols), width=250)\n\n# Regression line\nslope = Slope(gradient=slope_val, y_intercept=intercept, \n             line_color='red', line_dash='dashed', line_width=2.5)\nplot.add_layout(slope)\n\n# R¬≤ label\nr_squared_label = Label(x=70, y=10, x_units='screen', y_units='screen',\n                       text=f\"R¬≤ = {r_squared:.3f}\", text_font_size='13px',\n                       text_color='red', background_fill_color='white',\n                       background_fill_alpha=0.8)\nplot.add_layout(r_squared_label)\n\n# JavaScript callback with axis label updates\ncallback = CustomJS(args=dict(\n    source=source,\n    scatter=scatter,\n    slope=slope,\n    r_squared_label=r_squared_label,\n    plot=plot,\n    x_axis=x_axis,\n    y_axis=y_axis\n), code=\"\"\"\n    const x = x_axis.value;\n    const y = y_axis.value;\n    const x_data = source.data[x];\n    const y_data = source.data[y];\n    \n    // Calculate statistics\n    let x_sum = 0, y_sum = 0, xy_sum = 0, x2_sum = 0, y2_sum = 0;\n    const n = x_data.length;\n    \n    for (let i = 0; i &lt; n; i++) {\n        x_sum += x_data[i];\n        y_sum += y_data[i];\n        xy_sum += x_data[i] * y_data[i];\n        x2_sum += x_data[i] * x_data[i];\n        y2_sum += y_data[i] * y_data[i];\n    }\n    \n    // Calculate regression parameters\n    const slope_val = (n * xy_sum - x_sum * y_sum) / (n * x2_sum - x_sum * x_sum);\n    const intercept = (y_sum - slope_val * x_sum) / n;\n    const r_value = (n * xy_sum - x_sum * y_sum) / \n                   Math.sqrt((n * x2_sum - x_sum * x_sum) * (n * y2_sum - y_sum * y_sum));\n    const r_squared = r_value * r_value;\n    \n    // Update plot elements\n    scatter.glyph.x = {field: x};\n    scatter.glyph.y = {field: y};\n    slope.gradient = slope_val;\n    slope.y_intercept = intercept;\n    r_squared_label.text = `R¬≤ = ${r_squared.toFixed(3)}`;\n    \n    // Update axis labels\n    plot.xaxis.axis_label = `${x} (Count)`;\n    plot.yaxis.axis_label = `${y} (Count)`;\n\"\"\")\n\n# Connect callbacks\nx_axis.js_on_change('value', callback)\ny_axis.js_on_change('value', callback)\n\n# Layout\nlayout = column(\n    column(x_axis, y_axis, width=300),\n    plot\n)\n\n# Show the plot\nshow(layout)\n\n\n\n  \n\n\n\nWhen going through the different options and comparing them. One notices that there is close to zero correlation between any of the crimes and vehicle theft. Where as the big reason behind it is the incidents of the years 2003-2005 which are completely different for vehicle theft. If you look at an example as robbery and assault they are way more correlated (\\(r^2\\) value of 0.485) and generally if we compare most of the crimes with the total number of crimes, then they are fairly correlated. Examples being vandalism having \\(r^2=0.486\\) and larcency/theft having \\(r^2=0.700\\). Some of this might also be explained in larcency/theft and vandalism playing a bigger part of the crime incidents numbers\nOne interesting thing one could look at is if not including the years 2003-2005 how much that would impact it."
  }
]